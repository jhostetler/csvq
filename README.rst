csvq: Manipulate files in "comma separated value" (`.csv`) format
=================================================================

The `csvq` library is a small collection of utilities for manipulating files in comma separated value (`.csv`) format. The `.csv` format is commonly used for *ad hoc* data representation. As a graduate student I wrote dozens of one-off Python scripts to analyze `.csv` format data generated by machine learning experiments. I developed `csvq` to make these tasks easier.

`csvq` is developed with Python 3.5. It does **not** support Python 2.x.

Typical Usage
-------------

Use `import csvq` to expose the main `csvq` API. I recommend that you do **not** use `from csvq import *`, as the API contains functions with the same names as Python builtins.

The `csvq` API uses a "streaming" interface similar to UNIX pipes. Most operations can be chained together using the `|` (bitwise-or) operator. The implementation technique used for the streaming interface is due to the Pipe library:

  https://github.com/JulienPalard/Pipe

The streaming API includes the core operations of the relational algebra, basic functional programming constructs like `fold` and `map`, and functions for manipulating the structure of `csv` relations and converting them to Python data.

For example, a typical SQL statement::

  select (Name, Age) from Employees where Salary > 50000
	
is written in `csvq` like this::

  with stream_typed( "employees_typed.csv" ) as employees:
    result = (employees
           | select( lambda t: t.Salary > 50000 )
           | project( "Name", "Age" ))

(The data files used in these examples can be found in the `examples/` directory).

Notice how the `t` argument provided to the `select` predicate has a named field for the `Salary` column. This syntax may be used whenever a column name is a valid Python identifier. Tuples can also be indexed by string keys, as in `t("Name with spaces")`, or by positional index, as in `t[4]`.

`csvq` supports both typed and untyped relations. Type annotations are expressed by appending `:type` to column names, where `type` is one of the supported Python types: `{str, int, float}`. In untyped relations, everything has type `str`. To express the above query in an untyped relation, we need to use a type cast::

  with stream( "employees.csv" ) as employees:
    result = (employees
           | select( lambda t: int(t.Salary) > 50000 )
           | project( "Name", "Age" ))

Queries in `csvq` use a *lazy* evaluation strategy whenever possible. A Relation is modeled as an iterator over a collection of tuples, plus name and type information for the columns. Streaming operations (those that can be chained using the `|` operator) are implemented as iterator adapators.

A streamed relation is "consumed" the first time it is traversed. The simplest way to consume a relation is with standard Python iterable syntax::

  for t in relation:
    print( t ) # 't' is a Python tuple

API functions that takes a relation as a function parameter **consume that relation** (unless otherwise noted). For example, the `tuples()` function converts a relation to a list of Python tuples. Consider the following example::

  with stream_typed( "employees_typed.csv" ) as employees:
    a = tuples(employees)
    b = tuples(employees)
    assert( len(b) == 0 )
	
The second list is empty because `employees` was consumed to generate the first list. We can turn a lazy relation into an "eager" one with `evaluate()`. In the following example, both lists are populated::

  with stream_typed( "employees_typed.csv" ) as lazy:
    eager = evaluate( lazy )
    a = tuples(eager)
    b = tuples(eager)
    assert( a == b )

As a shortcut, we can read a relation into memory with the `load()` function::

  employees = load_typed( "employees_typed.csv" )
  a = tuples(employees)
  b = tuples(employees)
  assert( a == b )
	
Another example is the `natural_join()` function::

  with stream_typed( "employees_typed.csv" ) as employees,
       stream_typed( "parents_typed.csv" ) as parents:
    j = employees | rename( {"Name": "ChildName"} ) | natural_join( parents )
    assert( len(tuples(parents)) == 0 )

Notice that `parents` was consumed even though `j` has not yet been evaluated.

If Python complains that you've passed an argument of type `function` to operator `|`, that means that you've tried to use a non-streaming-enabled operation in a streaming context. For example::
  
  with stream_typed( "employees_typed.csv" ) as employees:
    # Right
    r = evaluate( employees )
	# WRONG
    # r = employees | evaluate

API Summary
-----------

Input and Output
  `stream`, `stream_typed`
    Lazy file input
  `load`, `load_typed`
    Eager file input
  `write`, `write_typed`, `write_without_headers`
    File output

Utility
  `evaluate`
    Evaluate query and store result in memory
  `sorted`, `EagerRelation.sort`
    Sort a relation (copy and in-place)

Relational Algebra
  `project`, `project_complement`
    Retain or drop named columns
  `rename`
    Rename columns
  `natural_join`
    Join on columns with the same name

Functional / Aggregation
  `map`
    Create new relation by mapping over rows
  `update`
    Map in-place
  `fold`
    Fold down to a single row
  `aggregate`
    Apply SQL-like aggregation operators

Structural
  `hcat`, `vcat`
    Horizontal and vertical concatenation
  `assign`
    Assign new values to columns
  `alter_type`
    Change column types

Conversion to Python types
  `scalar`, `vector`, `tuples`
    Extract first value, first row, or all tuples
	
Testing
-------

Execute

>>> python3 -m unittest csvq.test

from the project root directory to run unit tests.

Limitations
-----------

The `.csv` format parser is very basic. It does not validate input and it *always* interprets delimiters, regardless of whether they are quoted or escaped in any way. Values are parsed by applying the appropriate Python type constructor directly to the input string. I recommend that you use only valid Python identifiers as column names. Do *not* use quotes to surround names that are not valid identifiers or to indicate a string-valued field; the quotes will be interpreted as part of the column name or value.